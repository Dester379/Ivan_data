{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Сбор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#processing\n",
    "import pymysql.cursors \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pandas import ExcelWriter\n",
    "from datetime import datetime\n",
    "#import scikitplot as skplt\n",
    "#from xgboost.sklearn import XGBClassifier\n",
    "import scipy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#import IDF\n",
    "enc = OneHotEncoder()\n",
    "scaler = StandardScaler()\n",
    "label = LabelEncoder()\n",
    "#NLP\n",
    "#import nltk\n",
    "#import re\n",
    "#import pymorphy2\n",
    "#from nltk.corpus import stopwords\n",
    "#warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#visualisation\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#sns.set(style=\"white\", color_codes=True)\n",
    "#%matplotlib inline\n",
    "#vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#model \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, log_loss, f1_score, confusion_matrix, precision_score, recall_score, classification_report, accuracy_score\n",
    "#classificators\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Подключиться к базе данных\n",
    "def con():\n",
    "    conn = pymysql.connect(host='192.168.64.1', port=3306, user='i.serov', password='X3*1Uy(F', db='mysql')\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_npl = pd.read_sql('''\n",
    "select\n",
    "    c.id as credit_id, c.date_requested,\n",
    "                  ifnull(IF(c.status IN ('active','completed','expired'),\n",
    "                  (SELECT\n",
    "                    IF((COUNT(credit_payment.id) > 0 OR CURDATE() < LEAST(c.due_date,DATE(c.date_received) + INTERVAL 31 DAY) + INTERVAL 16 DAY),0,1)\n",
    "                  FROM br_release_moneyman.credit_payment\n",
    "                  WHERE ((credit_payment.credit_id = c.id) AND (credit_payment.payment_date <(LEAST(c.due_date,DATE(c.date_received) + INTERVAL 31 DAY) + INTERVAL 16 DAY)))),NULL),0)\n",
    "                  AS npl15,\n",
    "    pd.insurance_number\n",
    "from br_release_moneyman.credit c\n",
    "\tleft join br_release_moneyman.borrower b on c.borrower_id = b.id\n",
    "\tleft join br_release_moneyman.personal_data pd on b.personal_data_id = pd.id\n",
    "where c.status in ('ACTIVE', 'COMPLETED', 'EXPIRED', 'SOLD')\n",
    "ORDER BY insurance_number\n",
    "''', con=con())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inf = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 0)\n",
    "inf.columns = 'DadosBasicos_'+ inf.columns\n",
    "inf = inf.rename(columns={'DadosBasicos_Documento': 'Documento'})\n",
    "ralat = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 1) #povt\n",
    "ralat.columns = 'ralat_'+ ralat.columns\n",
    "ralat2 = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 2) #povt\n",
    "ralat2.columns = 'ralat2_'+ ralat2.columns\n",
    "phones = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 4) #povt\n",
    "phones.columns = 'phones_'+ phones.columns\n",
    "emails = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 5) #povt\n",
    "emails.columns = 'emails_'+ emails.columns\n",
    "socdem = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 6)\n",
    "socdem.columns = 'socdem_'+ socdem.columns\n",
    "socdem = socdem.rename(columns={'socdem_Documento': 'Documento'})\n",
    "soc_progr = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 7)\n",
    "soc_progr.columns = 'soc_progr_'+ soc_progr.columns\n",
    "soc_progr = soc_progr.rename(columns={'soc_progr_Documento': 'Documento'})\n",
    "profess = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 8)\n",
    "profess = profess.Documento\n",
    "profess_big = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 9)\n",
    "profess_big.columns = 'DadosProfissionais_ServidoresPu_'+ profess_big.columns\n",
    "profess_big = profess_big.rename(columns={'DadosProfissionais_ServidoresPu_Documento': 'Documento'})\n",
    "cobra = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 12)\n",
    "cobra.columns = 'cobra_'+ cobra.columns\n",
    "cobra = cobra.rename(columns={'cobra_Documento': 'Documento'})\n",
    "finance = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 14)\n",
    "finance.columns = 'finance_'+ finance.columns\n",
    "finance = finance.rename(columns={'finance_Documento': 'Documento'})\n",
    "present_online = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 17)\n",
    "present_online.columns = 'present_online_'+ present_online.columns\n",
    "present_online = present_online.rename(columns={'present_online_Documento': 'Documento'})\n",
    "vendors = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 18) #povt\n",
    "vendors.columns = 'vendors_'+ vendors.columns\n",
    "insurance = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 19)\n",
    "insurance.columns = 'insurance_'+ insurance.columns\n",
    "insurance = insurance.rename(columns={'insurance_Documento': 'Documento'})\n",
    "company = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 20)\n",
    "company.columns = 'company_'+ company.columns\n",
    "ABRT = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 21)  #povt\n",
    "ABRT.columns = 'ABRT_'+ ABRT.columns\n",
    "med_insur = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 22) #povt\n",
    "med_insur.columns = 'med_insur_'+ med_insur.columns\n",
    "inter = pd.read_excel('MoneyMan_BDC_Completo_12Dec17.xlsx', 23)\n",
    "inter.columns = 'inter_'+ inter.columns\n",
    "inter = inter.rename(columns={'inter_Documento': 'Documento'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#company\n",
    "company['company_Documento Empresa'] = company['company_Documento Empresa'].map(lambda x: 0 if x=='NO INFORMATION FOUND' else 1)\n",
    "company = company[['company_Documento', 'company_Documento Empresa']]\n",
    "company = company.rename(columns={'company_Documento': 'Documento'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relations\n",
    "rlt1 = ralat.pivot_table(index = ['ralat_Documento'], columns = 'ralat_Tipo do Relacionamento', aggfunc='size').reset_index()\n",
    "rlt1['ralat_Ultima Atualizacao'] = ralat.groupby('ralat_Documento').agg({'ralat_Ultima Atualizacao': 'max'}).reset_index()['ralat_Ultima Atualizacao']\n",
    "relat = rlt1\n",
    "relat = relat.rename(columns={'ralat_Documento': 'Documento'})\n",
    "rlt2 = ralat2.pivot_table(index = ['ralat2_Documento'], columns = 'ralat2_Tipo do Relacionamento', aggfunc='size').reset_index()\n",
    "rlt2['ralat2_Ultima Atualizacao'] = ralat2.groupby('ralat2_Documento').agg({'ralat2_Ultima Atualizacao': 'max'}).reset_index()['ralat2_Ultima Atualizacao']\n",
    "relat2 = rlt2\n",
    "relat2 = relat2.rename(columns={'ralat2_Documento': 'Documento'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#phones\n",
    "cnt = phones.groupby('phones_Documento').agg({'phones_Tipo': 'count'}).reset_index()\n",
    "sm = phones.groupby('phones_Documento').agg({'phones_Passagens': 'sum'}).reset_index()\n",
    "sm['phones_Ultima Atualizacao'] = phones.groupby('phones_Documento').agg({'phones_Ultima Atualizacao': 'max'}).reset_index()['phones_Ultima Atualizacao']\n",
    "sm['phones_Primeira Passagem'] = phones.groupby('phones_Documento').agg({'phones_Primeira Passagem': 'max'}).reset_index()['phones_Primeira Passagem']\n",
    "sm['phones_Ultima Passagem'] = phones.groupby('phones_Documento').agg({'phones_Ultima Passagem': 'max'}).reset_index()['phones_Ultima Passagem']\n",
    "phones['phones_Pessoas no Telefone'] = phones['phones_Pessoas no Telefone'].replace('10+', 10).map(lambda x: int(x))\n",
    "sm1 = phones.groupby('phones_Documento').agg({'phones_Pessoas no Telefone': 'sum'}).reset_index()\n",
    "phones = pd.merge(cnt, pd.merge(sm1, sm, how = 'outer', on = 'phones_Documento'), how = 'outer', on = 'phones_Documento')\n",
    "phones = phones.rename(columns={'phones_Tipo': 'phones_count'})\n",
    "phones = phones.rename(columns={'phones_Documento': 'Documento'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emails\n",
    "cnt = emails.groupby('emails_Documento').agg({'emails_Tipo': 'count'}).reset_index()\n",
    "sm = emails.groupby('emails_Documento').agg({'emails_Passagens': 'sum'}).reset_index()\n",
    "emails['emails_Pessoas no Email'] = emails['emails_Pessoas no Email'].replace('10+', 10).map(lambda x: int(x))\n",
    "sm1 = emails.groupby('emails_Documento').agg({'emails_Pessoas no Email': 'sum'}).reset_index()\n",
    "sm1['emails_Ultima Atualizacao'] = emails.groupby('emails_Documento').agg({'emails_Ultima Atualizacao': 'max'}).reset_index()['emails_Ultima Atualizacao']\n",
    "sm1['emails_Primeira Passagem'] = emails.groupby('emails_Documento').agg({'emails_Primeira Passagem': 'max'}).reset_index()['emails_Primeira Passagem']\n",
    "sm1['emails_Ultima Passagem'] = emails.groupby('emails_Documento').agg({'emails_Ultima Passagem': 'max'}).reset_index()['emails_Ultima Passagem']\n",
    "emails = pd.merge(cnt, pd.merge(sm1, sm, how = 'outer', on = 'emails_Documento'), how = 'outer', on = 'emails_Documento')\n",
    "emails = emails.rename(columns={'emails_Tipo': 'emails_count'})\n",
    "emails = emails.rename(columns={'emails_Documento': 'Documento'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ABRT\n",
    "ABRT['ABRT_DateLastUpdate'].fillna('01/01/2001', inplace = True)\n",
    "ABRT['ABRT_DateLastUpdate'] = ABRT['ABRT_DateLastUpdate'].map(lambda x: datetime.strptime(x, '%d/%m/%Y'))\n",
    "ABRT['ABRT_max_date'] = ABRT.groupby('ABRT_Documento')['ABRT_DateLastUpdate'].transform('max')\n",
    "ABRT['ABRT_min_date'] = ABRT.groupby('ABRT_Documento')['ABRT_DateLastUpdate'].transform('min')\n",
    "ABRT['ABRT_OfficialName'] = ABRT.groupby(['ABRT_Documento'])['ABRT_OfficialName'].transform('count')\n",
    "ABRT = ABRT[['ABRT_Documento', 'ABRT_OfficialName', 'ABRT_max_date', 'ABRT_min_date']].drop_duplicates()\n",
    "ABRT = ABRT.rename(columns={'ABRT_Documento': 'Documento'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#med insurance\n",
    "med_insur = pd.concat(\n",
    "    [med_insur, pd.get_dummies(med_insur.med_insur_Status)], axis=1)\n",
    "med_insur['med_insur_Nome'] = med_insur.groupby('med_insur_Documento')[\n",
    "    'med_insur_Nome'].transform('count')\n",
    "med_insur.med_insur_Operadora.fillna('noooo - noooo', inplace=True)\n",
    "med_insur = med_insur[med_insur.med_insur_Operadora != 'noooo - noooo']\n",
    "med_insur.med_insur_Operadora = med_insur.med_insur_Operadora.map(lambda x: x.split('-')[1])\n",
    "med_insur.med_insur_Operadora = label.fit_transform(\n",
    "    med_insur.med_insur_Operadora)\n",
    "med_insur['med_insur_Plano de Saude'] = med_insur[\n",
    "    'med_insur_Plano de Saude'].map(lambda x: x.split('-')[1])\n",
    "med_insur['med_insur_Plano de Saude'] = med_insur.groupby(\n",
    "    'med_insur_Plano de Saude')['med_insur_Plano de Saude'].transform('count')\n",
    "med_insur['med_insur_Caracteristicas do Plano'] = med_insur.groupby(\n",
    "    'med_insur_Caracteristicas do Plano')[\n",
    "        'med_insur_Caracteristicas do Plano'].transform('count')\n",
    "med_insur = med_insur[[\n",
    "    'med_insur_Documento', 'med_insur_Nome', 'med_insur_Status',\n",
    "    'med_insur_Data de Nascimento', 'med_insur_Operadora',\n",
    "    'med_insur_Plano de Saude', 'med_insur_Caracteristicas do Plano'\n",
    "]].sort_values('med_insur_Documento')\n",
    "med_insur['max_med_insur_Operadora'] = med_insur.groupby(\n",
    "    'med_insur_Documento')['med_insur_Operadora'].transform('max')\n",
    "med_insur['min_med_insur_Operadora'] = med_insur.groupby(\n",
    "    'med_insur_Documento')['med_insur_Operadora'].transform('min')\n",
    "med_insur['max_med_insur_Plano_de_Saude'] = med_insur.groupby('med_insur_Documento')[\n",
    "    'med_insur_Plano de Saude'].transform('max')\n",
    "med_insur['min_med_insur_Plano_de_Saude'] = med_insur.groupby('med_insur_Documento')[\n",
    "    'med_insur_Plano de Saude'].transform('min')\n",
    "med_insur['max_med_insur_Caracteristicas'] = med_insur.groupby('med_insur_Documento')[\n",
    "    'med_insur_Caracteristicas do Plano'].transform('max')\n",
    "med_insur['min_med_insur_Caracteristicas'] = med_insur.groupby('med_insur_Documento')[\n",
    "    'med_insur_Caracteristicas do Plano'].transform('min')\n",
    "med_insur = med_insur[[\n",
    "    'med_insur_Documento', 'med_insur_Nome', 'med_insur_Status',\n",
    "    'med_insur_Data de Nascimento', 'max_med_insur_Operadora',\n",
    "    'min_med_insur_Operadora', 'max_med_insur_Plano_de_Saude',\n",
    "    'min_med_insur_Plano_de_Saude', 'max_med_insur_Caracteristicas',\n",
    "    'min_med_insur_Caracteristicas'\n",
    "]].drop_duplicates()\n",
    "med_insur['med_insur_Data de Nascimento'] = med_insur['med_insur_Data de Nascimento'].map(\n",
    "    lambda x: datetime.strptime(x, '%d/%m/%Y'))\n",
    "med_insur['med_insur_Data de Nascimento'] = med_insur['med_insur_Data de Nascimento'].map(\n",
    "    lambda x: 2017 - x.year)\n",
    "med_insur = med_insur.rename(columns={'med_insur_Documento': 'Documento'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vendors['vendors_Data do Primeiro Anuncio'] = vendors.groupby('vendors_Documento')['vendors_Data do Primeiro Anuncio'].transform('min')\n",
    "vendors['vendors_Data do Ultimo Anuncio'] = vendors.groupby('vendors_Documento')['vendors_Data do Ultimo Anuncio'].transform('max')\n",
    "vendors['vendors_Total de Anuncios'] = vendors.groupby('vendors_Documento')['vendors_Total de Anuncios'].transform('mean')\n",
    "vendors['vendors_Maior Valor de Anuncio'] = vendors.groupby('vendors_Documento')['vendors_Maior Valor de Anuncio'].transform('max')\n",
    "vendors['vendors_Menor Valor de Anuncio'] = vendors.groupby('vendors_Documento')['vendors_Menor Valor de Anuncio'].transform('min')\n",
    "vendors['vendors_Valor Medio de Anuncio'] = vendors.groupby('vendors_Documento')['vendors_Valor Medio de Anuncio'].transform('mean')\n",
    "vendors['vendors_Anuncios na Categoria Principal'] = vendors.groupby('vendors_Documento')['vendors_Anuncios na Categoria Principal'].transform('mean')\n",
    "vendors['vendors_Valor do Ultimo Anuncio'] = vendors.groupby('vendors_Documento')['vendors_Valor do Ultimo Anuncio'].transform('max')\n",
    "vendors.vendors_Categorias = vendors.vendors_Categorias + ';'\n",
    "vendors.vendors_Categorias = vendors.groupby('vendors_Documento')['vendors_Categorias'].transform('sum')\n",
    "vendors['vendors_Categoria Principal'] = vendors['vendors_Categoria Principal'] + ';'\n",
    "vendors['vendors_Categoria Principal'] = vendors.groupby('vendors_Documento')['vendors_Categoria Principal'].transform('sum')\n",
    "vendors['vendors_Anuncios Ativos'] = vendors.groupby('vendors_Documento')['vendors_Anuncios Ativos'].transform('max')\n",
    "vendors['vendors_Anuncios nos Ultimos 30 Dias'] = vendors.groupby('vendors_Documento')['vendors_Anuncios nos Ultimos 30 Dias'].transform('max')\n",
    "vendors['vendors_Anuncios nos Ultimos 90 Dias'] = vendors.groupby('vendors_Documento')['vendors_Anuncios nos Ultimos 90 Dias'].transform('max')\n",
    "vendors['vendors_Anuncios nos Ultimos 180 Dias'] = vendors.groupby('vendors_Documento')['vendors_Anuncios nos Ultimos 180 Dias'].transform('max')\n",
    "vendors['vendors_Anuncios nos Ultimos 365 Dias'] = vendors.groupby('vendors_Documento')['vendors_Anuncios nos Ultimos 365 Dias'].transform('max')\n",
    "vendors['vendors_Anuncios na Categoria Principal'] = vendors.groupby('vendors_Documento')['vendors_Anuncios na Categoria Principal'].transform('max')\n",
    "vendors['vendors_Anuncios no Portal Principal'] = vendors.groupby('vendors_Documento')['vendors_Anuncios no Portal Principal'].transform('max')\n",
    "vendors = vendors.drop('vendors_Telefone', axis=1).drop_duplicates()\n",
    "vendors = vendors[(vendors.vendors_Documento!=22631908805) &  (vendors.vendors_Documento!=13960271735)]\n",
    "vendors = vendors.rename(columns={'vendors_Documento': 'Documento'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jn = pd.merge(\n",
    "    relat,\n",
    "    pd.merge(\n",
    "        inf,\n",
    "        pd.merge(\n",
    "            phones,\n",
    "            pd.merge(\n",
    "                emails,\n",
    "                pd.merge(\n",
    "                    socdem,\n",
    "                    pd.merge(\n",
    "                        soc_progr,\n",
    "                        pd.merge(\n",
    "                            profess_big,\n",
    "                            pd.merge(\n",
    "                                cobra,\n",
    "                                pd.merge(\n",
    "                                    present_online,\n",
    "                                    pd.merge(\n",
    "                                        vendors,\n",
    "                                        pd.merge(\n",
    "                                            insurance,\n",
    "                                            pd.merge(\n",
    "                                                company,\n",
    "                                                pd.merge(\n",
    "                                                    ABRT,\n",
    "                                                    pd.merge(\n",
    "                                                        med_insur,\n",
    "                                                        pd.merge(\n",
    "                                                            inter,\n",
    "                                                            relat2,\n",
    "                                                            how='outer',\n",
    "                                                            on='Documento'\n",
    "                                                        ),\n",
    "                                                        how='outer',\n",
    "                                                        on='Documento'),\n",
    "                                                    how='outer',\n",
    "                                                    on='Documento'),\n",
    "                                                how='outer',\n",
    "                                                on='Documento'),\n",
    "                                            how='outer',\n",
    "                                            on='Documento'),\n",
    "                                        how='outer',\n",
    "                                        on='Documento'),\n",
    "                                    how='outer',\n",
    "                                    on='Documento'),\n",
    "                                how='outer',\n",
    "                                on='Documento'),\n",
    "                            how='outer',\n",
    "                            on='Documento'),\n",
    "                        how='outer',\n",
    "                        on='Documento'),\n",
    "                    how='outer',\n",
    "                    on='Documento'),\n",
    "                how='outer',\n",
    "                on='Documento'),\n",
    "            how='outer',\n",
    "            on='Documento'),\n",
    "        how='outer',\n",
    "        on='Documento'),\n",
    "    how='outer',\n",
    "    on='Documento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_jn.copy()\n",
    "#df_jn = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_list = pd.read_excel('cpf_formatted.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, docs_list, how='left', on='Documento').drop(\n",
    "    ['q1', 'q2', 'q3', 'q4', 'q5', 'q6', 'Documento'], axis=1)\n",
    "df = df.rename(columns={'Documento formated': 'Documento'})\n",
    "df_npl = df_npl.rename(columns={'insurance_number': 'Documento'})\n",
    "df = pd.merge(df_npl, df, how='left', on='Documento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['DadosBasicos_Nome', 'DadosBasicos_Nome da Mae', 'DadosProfissionais_ServidoresPu_Ocupacao',\n",
    "       'DadosProfissionais_ServidoresPu_Entidade Governamental', 'DadosProfissionais_ServidoresPu_Ministerio',\n",
    "          'vendors_Portais','vendors_Categoria Principal',\n",
    "       'vendors_Categorias', 'vendors_Portal Principal',\n",
    "           'insurance_Nome', 'insurance_PIS',\n",
    "      'insurance_Motivo',\n",
    "       'insurance_Procedimento', 'insurance_Parcelas', 'insurance_Situaçőes',\n",
    "       'insurance_Datas de Disponibilidade', 'ABRT_max_date', 'ABRT_min_date']\n",
    "df = df.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates_to_check_1 = [\n",
    "    #inf\n",
    "    'DadosBasicos_Data de Nascimento','DadosBasicos_Data de Criacao','DadosBasicos_Ultima Atualizacao',\n",
    "    #relat12\n",
    "    'ralat_Ultima Atualizacao','ralat2_Ultima Atualizacao',\n",
    "    #phones\n",
    "    'phones_Ultima Atualizacao', 'phones_Primeira Passagem', 'phones_Ultima Passagem',\n",
    "    #emails\n",
    "    'emails_Ultima Atualizacao', 'emails_Primeira Passagem','emails_Ultima Passagem', \n",
    "    #socdem\n",
    "    'socdem_Data de Criacao', 'socdem_Ultima Atualizacao',\n",
    "    #cobra\n",
    "    'cobra_Data da Primeira Ocorrencia', 'cobra_Data da Ultima Ocorrencia',\n",
    "    #pres onl\n",
    "    'present_online_Primeira Passagem', 'present_online_Ultima Passagem',\n",
    "    #vendors\n",
    "    'vendors_Data do Primeiro Anuncio', 'vendors_Data do Ultimo Anuncio', \n",
    "]\n",
    "dates_to_check_2 = [\n",
    "    #profes big\n",
    "   'DadosProfissionais_ServidoresPu_Data de Criacao', 'DadosProfissionais_ServidoresPu_Ultima Atualizacao'  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_prep_1(columns):\n",
    "    for i in columns:\n",
    "        df[i] = df[i].replace('0001-01-01', '01-01-2001')\n",
    "        df[i] = df[i].replace('01-01-0001', '01-01-2001')        \n",
    "        df[i] = df[i].fillna('01-01-2001')\n",
    "        df[i] = df[i].map(lambda x: datetime.strptime(x, '%d-%m-%Y'))\n",
    "        df[i] = df.date_requested - df[i]\n",
    "        df[i] = df[i].map(lambda x: x.days)\n",
    "        \n",
    "def date_prep_2(columns):\n",
    "    for i in columns:\n",
    "        df[i] = df[i].replace('0001-01-01', '2001-01-01')\n",
    "        df[i] = df[i].replace('01-01-0001', '2001-01-01')        \n",
    "        df[i] = df[i].fillna('2001-01-01')\n",
    "        df[i] = df[i].map(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "        df[i] = df.date_requested - df[i]\n",
    "        df[i] = df[i].map(lambda x: x.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_prep_1(dates_to_check_1)\n",
    "date_prep_2(dates_to_check_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['credit_id', 'date_requested', 'Documento', 'BROTHER', 'HOUSEHOLD','NEIGHBOR','DadosBasicos_Signo',\n",
    "       'DadosProfissionais_ServidoresPu_Ultima Atualizacao', 'emails_Primeira Passagem','phones_Pessoas no Telefone',\n",
    "      'phones_Ultima Atualizacao','phones_Primeira Passagem','emails_Ultima Atualizacao','ralat_Ultima Atualizacao',\n",
    "      'present_online_Passagens','cobra_Data da Primeira Ocorrencia', 'cobra_Data da Ultima Ocorrencia',\n",
    "      'phones_Passagens','DadosBasicos_Ultima Atualizacao','phones_Ultima Passagem','emails_Ultima Passagem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('Bigdata_vars.xlsx')\n",
    "X.to_excel(writer,'Bigdata_vars', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''cat_vars = ['DadosBasicos_Status','DadosBasicos_Genero', 'DadosBasicos_Signo', 'DadosBasicos_Obito','socdem_Classe Social','socdem_Renda Estimada - BDC', 'socdem_Renda Media - IBGE',\n",
    "       'socdem_Renda Media - MTE', 'socdem_Escolaridade Media - IBGE',\n",
    "       'socdem_Escolaridade Media - MTE', 'DadosProfissionais_ServidoresPu_Faixa Salarial','DadosProfissionais_ServidoresPu_UF', \n",
    "           'finance_Renda Estimada',   'finance_Status da Restituicao', 'finance_Banco da Restituicao',\n",
    "           'present_online_Comprador Online','med_insur_Status',\n",
    "       'present_online_Vendedor Online','insurance_Situaçăo', 'insurance_Tempo de Serviço',\n",
    "           'inter_Nivel de Utilizacao de Cartao de Credito', 'inter_Programas de Fidelidade']\n",
    "for i in cat_vars:\n",
    "    df[i] = label.fit_transform(df[i].astype(str))''';"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "notify_time": "30",
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "331px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
