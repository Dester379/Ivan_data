{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.3.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.4 (default, Jan 28 2018 00:00:00)\n",
      "SparkSession available as 'spark'.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='pyspark-shell'\n",
    "os.environ[\"PYSPARK_PYTHON\"]='python3'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.4-src.zip'))\n",
    "os.environ[\"PYSPARK_PYTHON\"] = 'python3'\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())\n",
    "\n",
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import re\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, HashingTF, IDF\n",
    "from pyspark.sql.types import IntegerType\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"json\").load(\"/labs/lab07data/DO_record_per_line.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"json\").load(\"/labs/lab07data/DO_record_per_line.json\")\n",
    "regex = re.compile(r'[\\w\\d]{2,}', re.U)\n",
    "\n",
    "f1 = udf(lambda x: ' '.join(regex.findall(x.lower())))\n",
    "\n",
    "ndf = df.withColumn(\"ndesc\", f1(df[\"desc\"])).select('id', 'ndesc','lang')\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"ndesc\", outputCol=\"words\")\n",
    "tokenized = tokenizer.transform(ndf)\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "featurizedData = hashingTF.transform(tokenized)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "#rescaledData.show(10)\n",
    "\n",
    "def cos_sim_sp(a,b):\n",
    "    if a.norm(2) != 0 and  b.norm(2) != 0:\n",
    "        res = a.dot(b)/(a.norm(2)*b.norm(2))\n",
    "    else:\n",
    "        res = 0\n",
    "    return float(res)\n",
    "\n",
    "fun_cos = udf(lambda x: cos_sim_sp(x, course_1[0][\"features\"]), FloatType())\n",
    "\n",
    "ids_to_get = [15516,22777,13131,5660,965,877]\n",
    "data_to_save = {}\n",
    "for i in ids_to_get:\n",
    "    course_1 = rescaledData.filter(\"id = {}\".format(i)).select(\"features\").collect()\n",
    "    fun_cos = udf(lambda x: cos_sim_sp(x, course_1[0][\"features\"]), FloatType())\n",
    "    if i == 877 or i == 965:\n",
    "        data = rescaledData.withColumn(\"course_1\", fun_cos(rescaledData['features'])).filter(\"id != {}\".format(i)).filter(\"lang='ru'\").sort(desc(\"course_1\")).limit(10)\n",
    "    else:\n",
    "        data = rescaledData.withColumn(\"course_1\", fun_cos(rescaledData['features'])).filter(\"id != {}\".format(i)).sort(desc(\"course_1\")).limit(10)\n",
    "    my_ids = []\n",
    "    for i_like in data.select(\"id\").collect():\n",
    "        my_ids.append(i_like[\"id\"])\n",
    "    data_to_save[str(i)]=my_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('lab07.json', 'w') as fp:\n",
    "    json.dump(data_to_save, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
